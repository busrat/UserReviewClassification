{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_elmo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeYhf0FXEbGi"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET8Tu-26OSc-"
      },
      "source": [
        "#Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBx5NSAl-TiQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsApHHei8eGr",
        "outputId": "99589c65-9a4b-4bea-fd5d-527f28878e98"
      },
      "source": [
        "!pip install --upgrade simple_elmo"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: simple_elmo in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>1.8.1 in /usr/local/lib/python3.7/dist-packages (from simple_elmo) (5.0.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from simple_elmo) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from simple_elmo) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from simple_elmo) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from simple_elmo) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->simple_elmo) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->simple_elmo) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->simple_elmo) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->simple_elmo) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0E36OkM9ZDK",
        "outputId": "c1072d3e-d41e-4d49-dbcf-131901c04e3d"
      },
      "source": [
        "!wget https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json\n",
        "!wget https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-03 14:57:43--  https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json\n",
            "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.237.56\n",
            "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.237.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 336 [application/json]\n",
            "Saving to: ‘elmo_2x1024_128_2048cnn_1xhighway_options.json’\n",
            "\n",
            "elmo_2x1024_128_204 100%[===================>]     336  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-03 14:57:43 (20.1 MB/s) - ‘elmo_2x1024_128_2048cnn_1xhighway_options.json’ saved [336/336]\n",
            "\n",
            "--2021-06-03 14:57:43--  https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\n",
            "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.237.56\n",
            "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.237.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 54402456 (52M) [binary/octet-stream]\n",
            "Saving to: ‘elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5.1’\n",
            "\n",
            "elmo_2x1024_128_204 100%[===================>]  51.88M  25.7MB/s    in 2.0s    \n",
            "\n",
            "2021-06-03 14:57:46 (25.7 MB/s) - ‘elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5.1’ saved [54402456/54402456]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vdxsOKi99G-"
      },
      "source": [
        "!mv elmo_2x1024_128_2048cnn_1xhighway_options.json options.json"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhG63tqn8uTW"
      },
      "source": [
        "from simple_elmo import ElmoModel\n",
        "model = ElmoModel()\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "t624jXic_3Dy",
        "outputId": "540e0ca6-878d-4c5a-92ad-c394c342c6b5"
      },
      "source": [
        "#model.load('/content',max_batch_size=32)\n",
        "model.load('/content',max_batch_size=16)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 14:57:46,228 : INFO : Loading model from /content...\n",
            "2021-06-03 14:57:46,230 : INFO : No vocabulary file found in the model.\n",
            "2021-06-03 14:57:46,232 : INFO : No model.hdf5 file found. Using /content/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 as a model file.\n",
            "2021-06-03 14:57:46,233 : INFO : No vocabulary file provided; using special tokens only.\n",
            "2021-06-03 14:57:46,235 : INFO : We will cache the vocabulary of 3 tokens.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:909: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1700: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The model is now loaded.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih8Kp1wQ-HYs",
        "outputId": "8c27d58a-7716-4dbc-e095-192707800cd3"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ADV RE/app_reviews_all_annotated2.csv')\n",
        "df = df[['review', 'argument_cat', 'decision_cat']]\n",
        "\n",
        "# Remove missing rows\n",
        "df = df.dropna()\n",
        "\n",
        "df = df.groupby('argument_cat').filter(lambda x : len(x) > 1)\n",
        "df = df.groupby('decision_cat').filter(lambda x : len(x) > 1)\n",
        "\n",
        "# Convert to numeric for bert\n",
        "df['Argument'] = pd.Categorical(df['argument_cat'])\n",
        "df['Decision'] = pd.Categorical(df['decision_cat'])\n",
        "df['argument_cat'] = df['Argument'].cat.codes\n",
        "df['decision_cat'] = df['Decision'].cat.codes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 14:57:47,166 : INFO : NumExpr defaulting to 2 threads.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "aHPEQ9Ky-dPk",
        "outputId": "db4ca379-105c-4d3a-d654-bc6fa2ca1ee9"
      },
      "source": [
        "df2 = df.drop(columns=['Argument','Decision'])\n",
        "df2"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>argument_cat</th>\n",
              "      <th>decision_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Everyone should use it   Full Review</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Improve face detection please !!!   Full Rev...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>I think we just need more updates   Full Rev...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>if you're looking for an alternative for Pho...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>it's the best photo editor app i've ever see...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45986</th>\n",
              "      <td>OMG IT'S SO AWESOME YOU SHOULD TRY IT   Full...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46051</th>\n",
              "      <td>I litterly love this game i use to play this...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46076</th>\n",
              "      <td>Please make more levels. Other wise, it's go...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46077</th>\n",
              "      <td>awesome game worth the money!   Full Review</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46082</th>\n",
              "      <td>Exactly how Mario should be on mobile, defin...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2765 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  ...  decision_cat\n",
              "5                Everyone should use it   Full Review     ...             0\n",
              "37       Improve face detection please !!!   Full Rev...  ...             4\n",
              "192      I think we just need more updates   Full Rev...  ...             4\n",
              "201      if you're looking for an alternative for Pho...  ...             3\n",
              "221      it's the best photo editor app i've ever see...  ...             4\n",
              "...                                                  ...  ...           ...\n",
              "45986    OMG IT'S SO AWESOME YOU SHOULD TRY IT   Full...  ...             3\n",
              "46051    I litterly love this game i use to play this...  ...             0\n",
              "46076    Please make more levels. Other wise, it's go...  ...             4\n",
              "46077     awesome game worth the money!   Full Review     ...             1\n",
              "46082    Exactly how Mario should be on mobile, defin...  ...             1\n",
              "\n",
              "[2765 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3G9y8mj-tkk"
      },
      "source": [
        "train_df, test_df = train_test_split(df2, test_size = 0.1, stratify=df2[['argument_cat']])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_YnZzU_-z0q"
      },
      "source": [
        "x_train = train_df['review']\n",
        "y_train = train_df['argument_cat']\n",
        "x_test = test_df['review']\n",
        "y_test = test_df['argument_cat']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0glRZPSgWDBL",
        "outputId": "76912cb3-c203-4e8f-bf5b-88f1ba64e445"
      },
      "source": [
        "import pickle\n",
        "\n",
        "PATH = '/content/drive/MyDrive/ADV RE/'\n",
        "\n",
        "try:\n",
        "    x_train_embeddings = pickle.load(open(PATH + \"x_train_embeddings.pickle\", \"rb\" ))\n",
        "except (OSError, IOError) as e:\n",
        "    x_train_embeddings = model.get_elmo_vector_average(x_train.to_list())\n",
        "    pickle.dump(x_train_embeddings, open(PATH + \"x_train_embeddings.pickle\",'wb'))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 14:57:48,178 : INFO : Warming up ELMo on 16 sentences...\n",
            "2021-06-03 14:57:52,222 : INFO : Warming up finished.\n",
            "2021-06-03 14:57:52,243 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:57:53,522 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:57:54,449 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:57:55,484 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:57:57,167 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:57:58,855 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:00,461 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:01,748 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:02,647 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:04,208 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:05,715 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:06,745 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:08,196 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:09,284 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:10,461 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:11,811 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:15,012 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:16,146 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:18,828 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:19,852 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:21,588 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:22,662 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:24,628 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:25,695 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:26,775 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:28,538 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:29,592 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:30,539 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:31,825 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:33,482 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:34,388 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:36,132 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:36,850 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:37,828 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:40,231 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:41,529 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:42,475 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:43,130 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:44,177 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:45,396 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:46,343 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:48,081 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:49,301 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:50,422 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:51,508 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:52,988 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:54,004 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:55,104 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:56,417 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:57,626 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:58:58,325 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:00,168 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:02,110 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:02,959 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:04,013 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:05,507 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:06,510 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:08,232 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:09,733 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:10,927 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:12,030 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:13,047 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:14,372 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:15,306 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:15,993 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:16,714 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:17,949 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:18,898 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:19,598 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:20,549 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:21,870 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:23,611 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:24,831 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:26,667 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:28,264 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:29,670 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:30,592 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:31,595 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:33,941 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:34,961 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:36,281 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:37,526 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:38,630 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:39,777 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:40,874 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:42,006 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:43,970 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:45,046 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:45,763 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:47,364 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:48,615 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:49,845 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:50,985 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:52,450 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:53,663 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:54,545 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:55,549 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:56,622 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:58,170 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 14:59:59,606 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:00,560 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:01,610 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:02,353 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:03,730 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:04,698 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:08,567 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:09,486 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:10,778 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:11,690 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:12,952 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:14,179 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:15,923 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:16,506 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:17,655 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:18,611 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:19,282 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:20,301 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:22,134 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:23,019 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:24,188 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:24,725 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:27,315 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:29,310 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:30,354 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:31,184 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:32,108 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:32,984 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:33,743 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:34,781 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:35,826 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:37,333 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:38,225 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:38,806 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:40,868 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:41,967 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:42,963 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:46,877 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:48,171 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:49,578 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:50,513 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:53,392 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:54,556 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:56,144 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:57,156 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:59,178 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:00:59,754 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:00,460 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:01,863 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:02,909 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:03,930 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:04,991 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:06,163 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:07,586 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:08,588 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:09,824 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:10,788 : INFO : Texts in the current batch: 8\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxdr_zUv-4sI"
      },
      "source": [
        "#vectors = model.get_elmo_vector_average(x_train.to_list()[0:128])\n",
        "#x_train_embeddings = model.get_elmo_vector_average(x_train.to_list())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ezBv0ZzBqcZ",
        "outputId": "b2acc890-2d95-464d-af27-f21147415625"
      },
      "source": [
        "x_train_embeddings.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2488, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HJFhmPjWgI-",
        "outputId": "3227651f-48a0-4eaa-ec08-ea48e0021cc1"
      },
      "source": [
        "try:\n",
        "    x_test_embeddings = pickle.load(open(PATH + \"x_test_embeddings.pickle\", \"rb\" ))\n",
        "except (OSError, IOError) as e:\n",
        "    x_test_embeddings = model.get_elmo_vector_average(x_test.to_list())\n",
        "    pickle.dump(x_test_embeddings, open(PATH + \"x_test_embeddings.pickle\",'wb'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 15:01:13,187 : INFO : Warming up ELMo on 16 sentences...\n",
            "2021-06-03 15:01:14,635 : INFO : Warming up finished.\n",
            "2021-06-03 15:01:14,648 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:15,523 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:16,341 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:17,628 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:18,578 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:21,838 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:23,024 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:24,263 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:25,412 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:26,329 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:27,899 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:28,991 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:30,436 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:31,358 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:32,181 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:33,159 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:34,431 : INFO : Texts in the current batch: 16\n",
            "2021-06-03 15:01:36,580 : INFO : Texts in the current batch: 5\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH6tY0dYFtoM"
      },
      "source": [
        "#test_vectors = model.get_elmo_vector_average(x_test.to_list()[0:128])\n",
        "#x_test_embeddings = model.get_elmo_vector_average(x_test.to_list())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ7QA1vSCMsz",
        "outputId": "841dae19-dac9-418e-ba4b-8f6853077b34"
      },
      "source": [
        "inputs = tf.keras.Input(shape=256)\n",
        "x = tf.keras.layers.Dense(32, activation=tf.nn.relu)(inputs)\n",
        "\n",
        "arg = tf.keras.layers.Dense(4, activation=tf.nn.softmax, name='argument')(x)\n",
        "dec = tf.keras.layers.Dense(5, activation=tf.nn.softmax, name='decision')(x)\n",
        "outputs = {'argument': arg, 'decision': dec}\n",
        "\n",
        "my_model = tf.keras.Model(inputs=inputs, outputs=outputs, name='ELMo_For_App_Review_Classification')\n",
        "\n",
        "\n",
        "#arg = Dense(units=len(df.argument_cat.value_counts()), kernel_initializer=TruncatedNormal(stddev=conf.initializer_range), name='argument')(pooledOutput)\n",
        "#dec = Dense(units=len(df.decision_cat.value_counts()), kernel_initializer=TruncatedNormal(stddev=conf.initializer_range), name='decision')(pooledOutput)\n",
        "#outputs = {'argument': arg, 'decision': dec}\n",
        "\n",
        "my_model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ELMo_For_App_Review_Classification\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           8224        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "argument (Dense)                (None, 4)            132         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "decision (Dense)                (None, 5)            165         dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 8,521\n",
            "Trainable params: 8,521\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzGe29wuM3tr"
      },
      "source": [
        "optimizer = Adam(learning_rate=5e-05, epsilon=1e-08, decay=0.01, clipnorm=1.0)\n",
        "loss = {'argument': CategoricalCrossentropy(from_logits = True), 'decision': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'argument': CategoricalAccuracy('accuracy'), 'decision': CategoricalAccuracy('accuracy')}\n",
        "my_model.compile(optimizer = optimizer, loss = loss, metrics = metric)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH4OCBYJUNWy"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2_OXMbqPRdb",
        "outputId": "1dc86685-a09b-49f7-a666-4709f323d0ba"
      },
      "source": [
        "history = my_model.fit(x=x_train_embeddings, y={'argument': to_categorical(train_df.argument_cat), 'decision': to_categorical(train_df.decision_cat)},\n",
        "                    validation_split=0.1, batch_size=64, epochs=15)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2239 samples, validate on 249 samples\n",
            "Epoch 1/15\n",
            "2239/2239 [==============================] - 0s 146us/sample - loss: 2.9806 - argument_loss: 1.3714 - decision_loss: 1.6092 - argument_accuracy: 0.3042 - decision_accuracy: 0.0451 - val_loss: 2.9739 - val_argument_loss: 1.3654 - val_decision_loss: 1.6086 - val_argument_accuracy: 0.6145 - val_decision_accuracy: 0.0321\n",
            "Epoch 2/15\n",
            "1152/2239 [==============>...............] - ETA: 0s - loss: 2.9724 - argument_loss: 1.3639 - decision_loss: 1.6085 - argument_accuracy: 0.6606 - decision_accuracy: 0.0538"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2239/2239 [==============================] - 0s 56us/sample - loss: 2.9699 - argument_loss: 1.3618 - decision_loss: 1.6081 - argument_accuracy: 0.7075 - decision_accuracy: 0.0594 - val_loss: 2.9644 - val_argument_loss: 1.3568 - val_decision_loss: 1.6077 - val_argument_accuracy: 0.8193 - val_decision_accuracy: 0.0723\n",
            "Epoch 3/15\n",
            "2239/2239 [==============================] - 0s 51us/sample - loss: 2.9609 - argument_loss: 1.3537 - decision_loss: 1.6073 - argument_accuracy: 0.8392 - decision_accuracy: 0.1000 - val_loss: 2.9566 - val_argument_loss: 1.3496 - val_decision_loss: 1.6070 - val_argument_accuracy: 0.8554 - val_decision_accuracy: 0.1124\n",
            "Epoch 4/15\n",
            "2239/2239 [==============================] - 0s 63us/sample - loss: 2.9536 - argument_loss: 1.3468 - decision_loss: 1.6067 - argument_accuracy: 0.8665 - decision_accuracy: 0.1335 - val_loss: 2.9502 - val_argument_loss: 1.3435 - val_decision_loss: 1.6067 - val_argument_accuracy: 0.8434 - val_decision_accuracy: 0.1486\n",
            "Epoch 5/15\n",
            "2239/2239 [==============================] - 0s 60us/sample - loss: 2.9474 - argument_loss: 1.3410 - decision_loss: 1.6063 - argument_accuracy: 0.8598 - decision_accuracy: 0.1644 - val_loss: 2.9448 - val_argument_loss: 1.3383 - val_decision_loss: 1.6064 - val_argument_accuracy: 0.8313 - val_decision_accuracy: 0.1888\n",
            "Epoch 6/15\n",
            "2239/2239 [==============================] - 0s 56us/sample - loss: 2.9421 - argument_loss: 1.3361 - decision_loss: 1.6060 - argument_accuracy: 0.8508 - decision_accuracy: 0.1854 - val_loss: 2.9402 - val_argument_loss: 1.3340 - val_decision_loss: 1.6061 - val_argument_accuracy: 0.8233 - val_decision_accuracy: 0.1928\n",
            "Epoch 7/15\n",
            "2239/2239 [==============================] - 0s 56us/sample - loss: 2.9375 - argument_loss: 1.3318 - decision_loss: 1.6058 - argument_accuracy: 0.8517 - decision_accuracy: 0.2059 - val_loss: 2.9360 - val_argument_loss: 1.3301 - val_decision_loss: 1.6060 - val_argument_accuracy: 0.8193 - val_decision_accuracy: 0.2249\n",
            "Epoch 8/15\n",
            "2239/2239 [==============================] - 0s 55us/sample - loss: 2.9334 - argument_loss: 1.3279 - decision_loss: 1.6055 - argument_accuracy: 0.8499 - decision_accuracy: 0.2322 - val_loss: 2.9323 - val_argument_loss: 1.3267 - val_decision_loss: 1.6057 - val_argument_accuracy: 0.8193 - val_decision_accuracy: 0.2570\n",
            "Epoch 9/15\n",
            "2239/2239 [==============================] - 0s 52us/sample - loss: 2.9296 - argument_loss: 1.3244 - decision_loss: 1.6053 - argument_accuracy: 0.8490 - decision_accuracy: 0.2649 - val_loss: 2.9289 - val_argument_loss: 1.3234 - val_decision_loss: 1.6055 - val_argument_accuracy: 0.8193 - val_decision_accuracy: 0.3133\n",
            "Epoch 10/15\n",
            "2239/2239 [==============================] - 0s 51us/sample - loss: 2.9261 - argument_loss: 1.3211 - decision_loss: 1.6050 - argument_accuracy: 0.8486 - decision_accuracy: 0.3050 - val_loss: 2.9256 - val_argument_loss: 1.3203 - val_decision_loss: 1.6053 - val_argument_accuracy: 0.8193 - val_decision_accuracy: 0.3293\n",
            "Epoch 11/15\n",
            "2239/2239 [==============================] - 0s 64us/sample - loss: 2.9228 - argument_loss: 1.3180 - decision_loss: 1.6048 - argument_accuracy: 0.8486 - decision_accuracy: 0.3314 - val_loss: 2.9226 - val_argument_loss: 1.3175 - val_decision_loss: 1.6052 - val_argument_accuracy: 0.8193 - val_decision_accuracy: 0.3574\n",
            "Epoch 12/15\n",
            "2239/2239 [==============================] - 0s 64us/sample - loss: 2.9197 - argument_loss: 1.3152 - decision_loss: 1.6045 - argument_accuracy: 0.8486 - decision_accuracy: 0.3774 - val_loss: 2.9196 - val_argument_loss: 1.3149 - val_decision_loss: 1.6049 - val_argument_accuracy: 0.8193 - val_decision_accuracy: 0.3896\n",
            "Epoch 13/15\n",
            "2239/2239 [==============================] - 0s 52us/sample - loss: 2.9168 - argument_loss: 1.3125 - decision_loss: 1.6043 - argument_accuracy: 0.8486 - decision_accuracy: 0.4011 - val_loss: 2.9169 - val_argument_loss: 1.3124 - val_decision_loss: 1.6046 - val_argument_accuracy: 0.8193 - val_decision_accuracy: 0.4096\n",
            "Epoch 14/15\n",
            "2239/2239 [==============================] - 0s 56us/sample - loss: 2.9139 - argument_loss: 1.3099 - decision_loss: 1.6041 - argument_accuracy: 0.8486 - decision_accuracy: 0.4131 - val_loss: 2.9142 - val_argument_loss: 1.3097 - val_decision_loss: 1.6044 - val_argument_accuracy: 0.8193 - val_decision_accuracy: 0.4177\n",
            "Epoch 15/15\n",
            "2239/2239 [==============================] - 0s 51us/sample - loss: 2.9112 - argument_loss: 1.3073 - decision_loss: 1.6039 - argument_accuracy: 0.8486 - decision_accuracy: 0.4274 - val_loss: 2.9114 - val_argument_loss: 1.3071 - val_decision_loss: 1.6042 - val_argument_accuracy: 0.8193 - val_decision_accuracy: 0.4257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmgY1Rr_EQGw"
      },
      "source": [
        "#my_model.compile(optimizer='sgd',\n",
        "#              loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H67DpsE-E9IF"
      },
      "source": [
        "#epochs = 10\n",
        "##history = my_model.fit(\n",
        "##    vectors,\n",
        "##    epochs=epochs,y=y_train[0:128])\n",
        "#\n",
        "#history = my_model.fit(\n",
        "#    vectors,\n",
        "#    epochs=epochs,y=y_train)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwA_m3jjP9gJ"
      },
      "source": [
        "testArg = to_categorical(test_df['argument_cat'], 4)\n",
        "testDec = to_categorical(test_df['decision_cat'])\n",
        "\n",
        "modelEval = my_model.evaluate(x=x_test_embeddings,y={'argument': testArg, 'decision': testDec})"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqAGIg3vZ7Kk",
        "outputId": "4679a960-b232-41b6-b5ec-cb36a2ff2190"
      },
      "source": [
        "for x in zip(my_model.metrics_names,modelEval):\n",
        "  print(x)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('loss', 2.9115040775670904)\n",
            "('argument_loss', 1.3071111)\n",
            "('decision_loss', 1.6044036)\n",
            "('argument_accuracy', 0.84476537)\n",
            "('decision_accuracy', 0.41155234)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF8SDAJdFbAq"
      },
      "source": [
        "#loss, accuracy = my_model.evaluate(x=test_vectors,y=y_test[0:128])\n",
        "#loss, accuracy = my_model.evaluate(x=x_test_embeddings,y=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpJva7ttIcwa"
      },
      "source": [
        "#print(\"Test Loss: \" + str(loss))\n",
        "#print(\"Test Accuracy: \" + str(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
