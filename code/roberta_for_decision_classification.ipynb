{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "roberta_for_decision_classification.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6guYEySJYh6"
      },
      "source": [
        "# Using RoBERTa with Fastai Tutorial "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d1unLxrJYh-"
      },
      "source": [
        "This notebook follows the tutorial @ https://medium.com/@devkosal/using-roberta-with-fastai-for-nlp-7ed3fed21f6c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1WviXrTJ2lj",
        "outputId": "b986d729-0bea-4f25-ebf3-91df4f25d3fb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka1j15OzJ9C2",
        "outputId": "97c0514e-f748-402e-9be1-2aff7a93575b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUihnFVOJ-_4",
        "outputId": "cc6ad5fd-f974-4bfc-80b9-804fa659d32a"
      },
      "source": [
        "!pip install fastai"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastai in /usr/local/lib/python3.7/dist-packages (1.0.61)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.19.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from fastai) (0.9.1+cu101)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (20.9)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from fastai) (4.6.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from fastai) (2.7.3)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.8.1+cu101)\n",
            "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->fastai) (3.7.4.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (57.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->fastai) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:50:53.112411Z",
          "start_time": "2019-09-04T13:50:52.024302Z"
        },
        "id": "--5eQkOFJYiB"
      },
      "source": [
        "from fastai.text import *\n",
        "from fastai.metrics import *\n",
        "from transformers import RobertaTokenizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:50:53.119474Z",
          "start_time": "2019-09-04T13:50:53.113824Z"
        },
        "id": "fs3BbefPJYiD"
      },
      "source": [
        "# Creating a config object to store task specific information\n",
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "        \n",
        "config = Config(\n",
        "    testing=False,\n",
        "    seed = 2019,\n",
        "    roberta_model_name='roberta-base', # can also be exchnaged with roberta-large \n",
        "    max_lr=1e-5,\n",
        "    epochs=1,\n",
        "    use_fp16=False,\n",
        "    bs=4, \n",
        "    max_seq_len=256, \n",
        "    num_labels = 5,\n",
        "    hidden_dropout_prob=.05,\n",
        "    hidden_size=768, # 1024 for roberta-large\n",
        "    start_tok = \"<s>\",\n",
        "    end_tok = \"</s>\",\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:50:53.557101Z",
          "start_time": "2019-09-04T13:50:53.122045Z"
        },
        "id": "n-m5NvrZJYiE"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/app_reviews_all_annotated2.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:50:53.562452Z",
          "start_time": "2019-09-04T13:50:53.558919Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5jXv3QhJYiF",
        "outputId": "b627bdf8-65b2-4ea1-8e8e-2127635f6a76"
      },
      "source": [
        "if config.testing: df = df[:5000]\n",
        "print(df.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(46103, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:50:53.583364Z",
          "start_time": "2019-09-04T13:50:53.564068Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FolDSELOJYiH",
        "outputId": "733ba32e-5499-40fd-c72e-8187ca66f590"
      },
      "source": [
        "df = df[['review', 'decision_cat']]\n",
        "# Remove missing rows\n",
        "df = df.dropna()\n",
        "df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>decision_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Everyone should use it   Full Review</td>\n",
              "      <td>Acquiring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Improve face detection please !!!   Full Rev...</td>\n",
              "      <td>Requesting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>I think we just need more updates   Full Rev...</td>\n",
              "      <td>Requesting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>if you're looking for an alternative for Pho...</td>\n",
              "      <td>Recommendation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>it's the best photo editor app i've ever see...</td>\n",
              "      <td>Requesting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45986</th>\n",
              "      <td>OMG IT'S SO AWESOME YOU SHOULD TRY IT   Full...</td>\n",
              "      <td>Recommendation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46051</th>\n",
              "      <td>I litterly love this game i use to play this...</td>\n",
              "      <td>Acquiring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46076</th>\n",
              "      <td>Please make more levels. Other wise, it's go...</td>\n",
              "      <td>Requesting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46077</th>\n",
              "      <td>awesome game worth the money!   Full Review</td>\n",
              "      <td>Buying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46082</th>\n",
              "      <td>Exactly how Mario should be on mobile, defin...</td>\n",
              "      <td>Buying</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2772 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review    decision_cat\n",
              "5                Everyone should use it   Full Review          Acquiring\n",
              "37       Improve face detection please !!!   Full Rev...      Requesting\n",
              "192      I think we just need more updates   Full Rev...      Requesting\n",
              "201      if you're looking for an alternative for Pho...  Recommendation\n",
              "221      it's the best photo editor app i've ever see...      Requesting\n",
              "...                                                  ...             ...\n",
              "45986    OMG IT'S SO AWESOME YOU SHOULD TRY IT   Full...  Recommendation\n",
              "46051    I litterly love this game i use to play this...       Acquiring\n",
              "46076    Please make more levels. Other wise, it's go...      Requesting\n",
              "46077     awesome game worth the money!   Full Review             Buying\n",
              "46082    Exactly how Mario should be on mobile, defin...          Buying\n",
              "\n",
              "[2772 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:50:53.591663Z",
          "start_time": "2019-09-04T13:50:53.585091Z"
        },
        "id": "fY3B9gIPJYiI"
      },
      "source": [
        "feat_cols = \"review\"\n",
        "label_cols = \"decision_cat\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5luRAqM6JYiI"
      },
      "source": [
        "## Setting Up the Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:50:53.665067Z",
          "start_time": "2019-09-04T13:50:53.657647Z"
        },
        "id": "YoObWdU9JYiJ"
      },
      "source": [
        "class FastAiRobertaTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around RobertaTokenizer to be compatible with fastai\"\"\"\n",
        "    def __init__(self, tokenizer: RobertaTokenizer, max_seq_len: int=128, **kwargs): \n",
        "        self._pretrained_tokenizer = tokenizer\n",
        "        self.max_seq_len = max_seq_len \n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self \n",
        "    def tokenizer(self, t:str) -> List[str]: \n",
        "        \"\"\"Adds Roberta bos and eos tokens and limits the maximum sequence length\"\"\" \n",
        "        return [config.start_tok] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [config.end_tok]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:50:54.632414Z",
          "start_time": "2019-09-04T13:50:54.275831Z"
        },
        "id": "9HlXaucrJYiK"
      },
      "source": [
        "# create fastai tokenizer for roberta\n",
        "roberta_tok = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "fastai_tokenizer = Tokenizer(tok_func=FastAiRobertaTokenizer(roberta_tok, max_seq_len=config.max_seq_len), \n",
        "                             pre_rules=[], post_rules=[])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:50:55.213017Z",
          "start_time": "2019-09-04T13:50:55.095284Z"
        },
        "id": "Avr2TSPQJYiL"
      },
      "source": [
        "# create fastai vocabulary for roberta\n",
        "path = Path()\n",
        "roberta_tok.save_vocabulary(path)\n",
        "\n",
        "with open('vocab.json', 'r') as f:\n",
        "    roberta_vocab_dict = json.load(f)\n",
        "    \n",
        "fastai_roberta_vocab = Vocab(list(roberta_vocab_dict.keys()))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:50:55.920906Z",
          "start_time": "2019-09-04T13:50:55.914824Z"
        },
        "id": "VrJHtvYXJYiL"
      },
      "source": [
        "# Setting up pre-processors\n",
        "class RobertaTokenizeProcessor(TokenizeProcessor):\n",
        "    def __init__(self, tokenizer):\n",
        "         super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "class RobertaNumericalizeProcessor(NumericalizeProcessor):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "\n",
        "def get_roberta_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n",
        "    \"\"\"\n",
        "    Constructing preprocessors for Roberta\n",
        "    We remove sos and eos tokens since we add that ourselves in the tokenizer.\n",
        "    We also use a custom vocabulary to match the numericalization with the original Roberta model.\n",
        "    \"\"\"\n",
        "    return [RobertaTokenizeProcessor(tokenizer=tokenizer), RobertaNumericalizeProcessor(vocab=vocab)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_Z4JxO8JYiM"
      },
      "source": [
        "## Setting up the DataBunch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:50:57.966052Z",
          "start_time": "2019-09-04T13:50:57.959106Z"
        },
        "id": "dHWtX46QJYiM"
      },
      "source": [
        "# Creating a Roberta specific DataBunch class\n",
        "class RobertaDataBunch(TextDataBunch):\n",
        "    \"Create a `TextDataBunch` suitable for training Roberta\"\n",
        "    @classmethod\n",
        "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=64, val_bs:int=None, pad_idx=1,\n",
        "               pad_first=True, device:torch.device=None, no_check:bool=False, backwards:bool=False, \n",
        "               dl_tfms:Optional[Collection[Callable]]=None, **dl_kwargs) -> DataBunch:\n",
        "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
        "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
        "        val_bs = ifnone(val_bs, bs)\n",
        "        collate_fn = partial(pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
        "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs)\n",
        "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
        "        dataloaders = [train_dl]\n",
        "        for ds in datasets[1:]:\n",
        "            lengths = [len(t) for t in ds.x.items]\n",
        "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
        "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
        "        return cls(*dataloaders, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:50:58.992534Z",
          "start_time": "2019-09-04T13:50:58.986024Z"
        },
        "id": "WEkXxmURJYiM"
      },
      "source": [
        "class RobertaTextList(TextList):\n",
        "    _bunch = RobertaDataBunch\n",
        "    _label_cls = TextList"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:51:22.079406Z",
          "start_time": "2019-09-04T13:51:00.215358Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "oSblHcE9JYiN",
        "outputId": "0f3b6fa2-f2f5-4587-b8fb-28932e0eb545"
      },
      "source": [
        "# loading the tokenizer and vocab processors\n",
        "processor = get_roberta_processor(tokenizer=fastai_tokenizer, vocab=fastai_roberta_vocab)\n",
        "\n",
        "# creating our databunch \n",
        "data = RobertaTextList.from_df(df, \".\", cols=feat_cols, processor=processor) \\\n",
        "    .split_by_rand_pct(seed=config.seed) \\\n",
        "    .label_from_df(cols=label_cols,label_cls=CategoryList) \\\n",
        "    .databunch(bs=config.bs, pad_first=False, pad_idx=0)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X18HH53TJYiO"
      },
      "source": [
        "# Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:54:26.664096Z",
          "start_time": "2019-09-04T13:54:26.657203Z"
        },
        "id": "J9PKVSdXJYiO"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import RobertaModel\n",
        "\n",
        "# defining our model architecture \n",
        "class CustomRobertaModel(nn.Module):\n",
        "    def __init__(self,num_labels=2):\n",
        "        super(CustomRobertaModel,self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.roberta = RobertaModel.from_pretrained(config.roberta_model_name)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels) # defining final output layer\n",
        "        \n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _ , pooled_output = self.roberta(input_ids, token_type_ids, attention_mask,return_dict=False) # \n",
        "        logits = self.classifier(pooled_output)        \n",
        "        return logits"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-04T13:54:37.375403Z",
          "start_time": "2019-09-04T13:54:34.031342Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ws4SfJvJYiO",
        "outputId": "b8def28a-bb52-47e6-c610-abf10cff9300"
      },
      "source": [
        "roberta_model = CustomRobertaModel(num_labels=config.num_labels)\n",
        "\n",
        "learn = Learner(data, roberta_model, metrics=[accuracy])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-02T14:20:31.006732Z",
          "start_time": "2019-09-02T14:14:45.072892Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "A8gerlfLJYiO",
        "outputId": "c39d86fb-c692-4eed-fd6b-79476bcb1e80"
      },
      "source": [
        "learn.model.roberta.train() # setting roberta to train as it is in eval mode by default\n",
        "learn.fit_one_cycle(config.epochs, max_lr=config.max_lr)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.451299</td>\n",
              "      <td>0.302609</td>\n",
              "      <td>0.916968</td>\n",
              "      <td>00:53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1bss5ljJYiP"
      },
      "source": [
        "# Getting Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-02T14:11:19.976614Z",
          "start_time": "2019-09-02T14:11:19.970844Z"
        },
        "id": "StOekhpnJYiP"
      },
      "source": [
        "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
        "    learn.model.roberta.eval()\n",
        "    preds = learn.get_preds(ds_type)[0].detach().cpu().numpy()\n",
        "    sampler = [i for i in data.dl(ds_type).sampler]\n",
        "    reverse_sampler = np.argsort(sampler)\n",
        "    ordered_preds = preds[reverse_sampler, :]\n",
        "    pred_values = np.argmax(ordered_preds, axis=1)\n",
        "    return ordered_preds, pred_values"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-02T14:11:40.835200Z",
          "start_time": "2019-09-02T14:11:20.102674Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qtxX-oZmJYiP",
        "outputId": "7524f9bf-b1c8-49ac-a033-6190bab24918"
      },
      "source": [
        "preds, pred_values = get_preds_as_nparray(DatasetType.Valid)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-02T14:11:40.840225Z",
          "start_time": "2019-09-02T14:11:40.837056Z"
        },
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS691AQeJYiR",
        "outputId": "675f5663-654e-4a68-a380-6d03a3f369a6"
      },
      "source": [
        "# accuracy on valid\n",
        "(pred_values == data.valid_ds.y.items).mean()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9169675090252708"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNesXCEZVK-s",
        "outputId": "d8c451a5-c4da-4f06-be29-406e81ed4ff5"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "y_test = data.valid_ds.y.items\n",
        "y_pred = pred_values\n",
        "\n",
        "print('Confusion matrix:')\n",
        "print(confusion_matrix(y_test,y_pred,labels=[0,1,2,3,4]))\n",
        "print()\n",
        "print('Classification report:')\n",
        "print(classification_report(y_test,y_pred,labels=[0,1,2,3,4],target_names=['Acquiring','Buying','Rating','Recommendation','Requesting']))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[240   2   2  11   7]\n",
            " [  3  14   1   3   1]\n",
            " [  0   0  73   0   0]\n",
            " [  5   1   2 129   0]\n",
            " [  3   0   3   2  52]]\n",
            "\n",
            "Classification report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     Acquiring       0.96      0.92      0.94       262\n",
            "        Buying       0.82      0.64      0.72        22\n",
            "        Rating       0.90      1.00      0.95        73\n",
            "Recommendation       0.89      0.94      0.91       137\n",
            "    Requesting       0.87      0.87      0.87        60\n",
            "\n",
            "      accuracy                           0.92       554\n",
            "     macro avg       0.89      0.87      0.88       554\n",
            "  weighted avg       0.92      0.92      0.92       554\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7vwPNUJJYiR"
      },
      "source": [
        "# Optional: Saving/Loading the model weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUEk57PfJYiR"
      },
      "source": [
        "Once you are satisfied with training, you can use the following methods to save and load your pretrained weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm0KLY-DJYiR"
      },
      "source": [
        "def save_model(learner, file_name):\n",
        "    st = learner.model.state_dict()\n",
        "    torch.save(st, file_name) # will save model in current dir # backend is pickle \n",
        "\n",
        "def load_model(learner, file_name):\n",
        "    st = torch.load(file_name)\n",
        "    learner.model.load_state_dict(st)\n",
        "\n",
        "# monkey patching Learner methods to save and load model file\n",
        "Learner.save_model = save_model\n",
        "Learner.load_model = load_model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOQmUW4IJYiR"
      },
      "source": [
        "# learn.save_model(\"my_model.pth\")\n",
        "\n",
        "# learn.load_model(\"my_model.pth\")"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}