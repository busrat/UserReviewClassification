{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvbwu3oCB3MH"
      },
      "source": [
        "!pip install transformers\n",
        "# !pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2DKQmWpB7sQ"
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M1R55dYB-GB"
      },
      "source": [
        "# Import data\n",
        "df = pd.read_csv('app_reviews_all_annotated2.csv')\n",
        "df = df[['review', 'argument_cat', 'decision_cat']]\n",
        "\n",
        "# Remove missing rows\n",
        "df = df.dropna()\n",
        "\n",
        "# Convert to numeric for bert\n",
        "df['Argument'] = pd.Categorical(df['argument_cat'])\n",
        "df['Decision'] = pd.Categorical(df['decision_cat'])\n",
        "df['argument_cat'] = df['Argument'].cat.codes\n",
        "df['decision_cat'] = df['Decision'].cat.codes\n",
        "\n",
        "# Split into training and testing \n",
        "df, df_test = train_test_split(df, test_size = 0.2, stratify=df[['argument_cat']])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGTVvGjlCDHd",
        "outputId": "07572c4b-77bd-49c9-acca-ef576e58cafa"
      },
      "source": [
        "# BERT model\n",
        "modelName = 'bert-base-uncased'\n",
        "maxLen = 100\n",
        "conf = BertConfig.from_pretrained(modelName)\n",
        "conf.output_hidden_states = False\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = modelName, config = conf)\n",
        "\n",
        "# Load transformer BERT model\n",
        "transformerModel = TFBertModel.from_pretrained(modelName, config = conf)\n",
        "\n",
        "bert = transformerModel.layers[0]\n",
        "inputIds = Input(shape=(maxLen,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': inputIds}\n",
        "\n",
        "bertModel = bert(inputs)[1]\n",
        "dropout = Dropout(conf.hidden_dropout_prob, name='pooled_output')\n",
        "pooledOutput = dropout(bertModel, training=False)\n",
        "\n",
        "arg = Dense(units=len(df.argument_cat.value_counts()), kernel_initializer=TruncatedNormal(stddev=conf.initializer_range), name='argument')(pooledOutput)\n",
        "dec = Dense(units=len(df.decision_cat.value_counts()), kernel_initializer=TruncatedNormal(stddev=conf.initializer_range), name='decision')(pooledOutput)\n",
        "outputs = {'argument': arg, 'decision': dec}\n",
        "\n",
        "# Show model\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_For_App_Review_Classification')\n",
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"BERT_For_App_Review_Classification\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert (TFBertMainLayer)          TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pooled_output (Dropout)         (None, 768)          0           bert[0][1]                       \n",
            "__________________________________________________________________________________________________\n",
            "argument (Dense)                (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decision (Dense)                (None, 5)            3845        pooled_output[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 109,489,161\n",
            "Trainable params: 109,489,161\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heBO_9Lq-cBJ",
        "outputId": "6e10be2b-e5b0-4710-b142-9df0bfa666e2"
      },
      "source": [
        "# Training\n",
        "optimizer = Adam(learning_rate=5e-05, epsilon=1e-08, decay=0.01, clipnorm=1.0)\n",
        "loss = {'argument': CategoricalCrossentropy(from_logits = True), 'decision': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'argument': CategoricalAccuracy('accuracy'), 'decision': CategoricalAccuracy('accuracy')}\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = metric)\n",
        "\n",
        "x = tokenizer(text=df.review.to_list(), add_special_tokens=True, max_length=maxLen, \n",
        "              truncation=True, padding=True, return_tensors='tf', return_token_type_ids = False,\n",
        "              return_attention_mask = True, verbose = True)\n",
        "\n",
        "history = model.fit(x={'input_ids': x['input_ids']}, y={'argument': to_categorical(df.argument_cat), 'decision': to_categorical(df.decision_cat)},\n",
        "                    validation_split=0.2, batch_size=64, epochs=10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "28/28 [==============================] - 55s 1s/step - loss: 1.9199 - argument_loss: 0.5166 - decision_loss: 1.4033 - argument_accuracy: 0.8332 - decision_accuracy: 0.4132 - val_loss: 1.6566 - val_argument_loss: 0.3390 - val_decision_loss: 1.3176 - val_argument_accuracy: 0.8691 - val_decision_accuracy: 0.4808\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 35s 1s/step - loss: 1.6145 - argument_loss: 0.2988 - decision_loss: 1.3157 - argument_accuracy: 0.8847 - decision_accuracy: 0.4698 - val_loss: 1.5432 - val_argument_loss: 0.3082 - val_decision_loss: 1.2350 - val_argument_accuracy: 0.8736 - val_decision_accuracy: 0.5056\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 35s 1s/step - loss: 1.4113 - argument_loss: 0.2729 - decision_loss: 1.1384 - argument_accuracy: 0.9073 - decision_accuracy: 0.5591 - val_loss: 1.2120 - val_argument_loss: 0.2788 - val_decision_loss: 0.9332 - val_argument_accuracy: 0.8871 - val_decision_accuracy: 0.6591\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.9718 - argument_loss: 0.2373 - decision_loss: 0.7346 - argument_accuracy: 0.9305 - decision_accuracy: 0.7886 - val_loss: 0.8682 - val_argument_loss: 0.2996 - val_decision_loss: 0.5687 - val_argument_accuracy: 0.8939 - val_decision_accuracy: 0.8172\n",
            "Epoch 5/10\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.6559 - argument_loss: 0.2086 - decision_loss: 0.4473 - argument_accuracy: 0.9350 - decision_accuracy: 0.8847 - val_loss: 0.6809 - val_argument_loss: 0.2669 - val_decision_loss: 0.4140 - val_argument_accuracy: 0.9052 - val_decision_accuracy: 0.8804\n",
            "Epoch 6/10\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.4467 - argument_loss: 0.1672 - decision_loss: 0.2795 - argument_accuracy: 0.9553 - decision_accuracy: 0.9429 - val_loss: 0.6432 - val_argument_loss: 0.2725 - val_decision_loss: 0.3707 - val_argument_accuracy: 0.8984 - val_decision_accuracy: 0.8962\n",
            "Epoch 7/10\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.3161 - argument_loss: 0.1305 - decision_loss: 0.1856 - argument_accuracy: 0.9706 - decision_accuracy: 0.9683 - val_loss: 0.6309 - val_argument_loss: 0.2871 - val_decision_loss: 0.3437 - val_argument_accuracy: 0.8939 - val_decision_accuracy: 0.8939\n",
            "Epoch 8/10\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.2284 - argument_loss: 0.0947 - decision_loss: 0.1337 - argument_accuracy: 0.9808 - decision_accuracy: 0.9802 - val_loss: 0.6036 - val_argument_loss: 0.2765 - val_decision_loss: 0.3271 - val_argument_accuracy: 0.9029 - val_decision_accuracy: 0.9052\n",
            "Epoch 9/10\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.1833 - argument_loss: 0.0807 - decision_loss: 0.1027 - argument_accuracy: 0.9836 - decision_accuracy: 0.9859 - val_loss: 0.6333 - val_argument_loss: 0.3039 - val_decision_loss: 0.3294 - val_argument_accuracy: 0.8871 - val_decision_accuracy: 0.8984\n",
            "Epoch 10/10\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.1386 - argument_loss: 0.0602 - decision_loss: 0.0784 - argument_accuracy: 0.9921 - decision_accuracy: 0.9910 - val_loss: 0.6498 - val_argument_loss: 0.3236 - val_decision_loss: 0.3262 - val_argument_accuracy: 0.8939 - val_decision_accuracy: 0.9007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2kiSeCDBDXY",
        "outputId": "d6336796-d058-4f9f-9187-461c89e309ff"
      },
      "source": [
        "# Evaluation\n",
        "testArg = to_categorical(df_test['argument_cat'], 4)\n",
        "testDec = to_categorical(df_test['decision_cat'])\n",
        "testReview = tokenizer(text=df_test['review'].to_list(), add_special_tokens=True,\n",
        "                         max_length=maxLen, truncation=True, padding=True, \n",
        "                         return_tensors='tf', return_token_type_ids = False,\n",
        "                         return_attention_mask = False, verbose = True)\n",
        "modelEval = model.evaluate(x={'input_ids': testReview['input_ids']},\n",
        "                                 y={'argument': testArg, 'decision': testDec})"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 4s 193ms/step - loss: 0.7137 - argument_loss: 0.3119 - decision_loss: 0.4018 - argument_accuracy: 0.8861 - decision_accuracy: 0.8987\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
