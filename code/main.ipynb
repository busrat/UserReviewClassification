{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvbwu3oCB3MH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5905586a-479b-4a5e-d759-be8a064e5ff6"
      },
      "source": [
        "!pip install transformers\n",
        "# !pip install tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 26.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 35.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 41.9MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2DKQmWpB7sQ"
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M1R55dYB-GB"
      },
      "source": [
        "# Import data\n",
        "df = pd.read_csv('app_reviews_all_annotated2.csv')\n",
        "df = df[['review', 'argument_cat', 'decision_cat']]\n",
        "\n",
        "# Remove missing rows\n",
        "df = df.dropna()\n",
        "\n",
        "df = df.groupby('argument_cat').filter(lambda x : len(x) > 1)\n",
        "df = df.groupby('decision_cat').filter(lambda x : len(x) > 1)\n",
        "\n",
        "# Convert to numeric for bert\n",
        "df['Argument'] = pd.Categorical(df['argument_cat'])\n",
        "df['Decision'] = pd.Categorical(df['decision_cat'])\n",
        "df['argument_cat'] = df['Argument'].cat.codes\n",
        "df['decision_cat'] = df['Decision'].cat.codes\n",
        "\n",
        "# Split into training and testing \n",
        "df, df_test = train_test_split(df, test_size = 0.1, stratify=df[['argument_cat']])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGTVvGjlCDHd",
        "outputId": "33b512b2-46e0-4add-a93f-ca87edd690d2"
      },
      "source": [
        "# BERT model\n",
        "modelName = 'bert-base-uncased'\n",
        "maxLen = 100\n",
        "conf = BertConfig.from_pretrained(modelName)\n",
        "conf.output_hidden_states = False\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = modelName, config = conf)\n",
        "\n",
        "# Load transformer BERT model\n",
        "transformerModel = TFBertModel.from_pretrained(modelName, config = conf)\n",
        "\n",
        "bert = transformerModel.layers[0]\n",
        "inputIds = Input(shape=(maxLen,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': inputIds}\n",
        "\n",
        "bertModel = bert(inputs)[1]\n",
        "dropout = Dropout(conf.hidden_dropout_prob, name='pooled_output')\n",
        "pooledOutput = dropout(bertModel, training=False)\n",
        "\n",
        "arg = Dense(units=len(df.argument_cat.value_counts()), kernel_initializer=TruncatedNormal(stddev=conf.initializer_range), name='argument')(pooledOutput)\n",
        "dec = Dense(units=len(df.decision_cat.value_counts()), kernel_initializer=TruncatedNormal(stddev=conf.initializer_range), name='decision')(pooledOutput)\n",
        "outputs = {'argument': arg, 'decision': dec}\n",
        "\n",
        "# Show model\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_For_App_Review_Classification')\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"BERT_For_App_Review_Classification\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert (TFBertMainLayer)          TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pooled_output (Dropout)         (None, 768)          0           bert[0][1]                       \n",
            "__________________________________________________________________________________________________\n",
            "argument (Dense)                (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decision (Dense)                (None, 5)            3845        pooled_output[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 109,489,161\n",
            "Trainable params: 109,489,161\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heBO_9Lq-cBJ",
        "outputId": "b6a3ae75-d226-4bc0-ee69-8f89e58205c9"
      },
      "source": [
        "# Training\n",
        "optimizer = Adam(learning_rate=5e-05, epsilon=1e-08, decay=0.01, clipnorm=1.0)\n",
        "loss = {'argument': CategoricalCrossentropy(from_logits = True), 'decision': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'argument': CategoricalAccuracy('accuracy'), 'decision': CategoricalAccuracy('accuracy')}\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = metric)\n",
        "\n",
        "x = tokenizer(text=df.review.to_list(), add_special_tokens=True, max_length=maxLen, \n",
        "              truncation=True, padding=True, return_tensors='tf', return_token_type_ids = False,\n",
        "              return_attention_mask = True, verbose = True)\n",
        "\n",
        "history = model.fit(x={'input_ids': x['input_ids']}, y={'argument': to_categorical(df.argument_cat), 'decision': to_categorical(df.decision_cat)},\n",
        "                    validation_split=0.1, batch_size=64, epochs=15)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "35/35 [==============================] - 68s 1s/step - loss: 1.9945 - argument_loss: 0.5839 - decision_loss: 1.4106 - argument_accuracy: 0.8115 - decision_accuracy: 0.4149 - val_loss: 1.7355 - val_argument_loss: 0.3684 - val_decision_loss: 1.3672 - val_argument_accuracy: 0.8594 - val_decision_accuracy: 0.4137\n",
            "Epoch 2/15\n",
            "35/35 [==============================] - 44s 1s/step - loss: 1.5216 - argument_loss: 0.3347 - decision_loss: 1.1869 - argument_accuracy: 0.8736 - decision_accuracy: 0.5266 - val_loss: 1.2530 - val_argument_loss: 0.3678 - val_decision_loss: 0.8852 - val_argument_accuracy: 0.8715 - val_decision_accuracy: 0.7309\n",
            "Epoch 3/15\n",
            "35/35 [==============================] - 45s 1s/step - loss: 0.9410 - argument_loss: 0.2884 - decision_loss: 0.6526 - argument_accuracy: 0.9031 - decision_accuracy: 0.7990 - val_loss: 0.7870 - val_argument_loss: 0.3109 - val_decision_loss: 0.4761 - val_argument_accuracy: 0.8956 - val_decision_accuracy: 0.8474\n",
            "Epoch 4/15\n",
            "35/35 [==============================] - 45s 1s/step - loss: 0.5715 - argument_loss: 0.2342 - decision_loss: 0.3373 - argument_accuracy: 0.9201 - decision_accuracy: 0.9218 - val_loss: 0.6518 - val_argument_loss: 0.2867 - val_decision_loss: 0.3651 - val_argument_accuracy: 0.8956 - val_decision_accuracy: 0.8835\n",
            "Epoch 5/15\n",
            "35/35 [==============================] - 45s 1s/step - loss: 0.3719 - argument_loss: 0.1704 - decision_loss: 0.2016 - argument_accuracy: 0.9469 - decision_accuracy: 0.9558 - val_loss: 0.6639 - val_argument_loss: 0.3465 - val_decision_loss: 0.3174 - val_argument_accuracy: 0.8916 - val_decision_accuracy: 0.8956\n",
            "Epoch 6/15\n",
            "35/35 [==============================] - 45s 1s/step - loss: 0.2764 - argument_loss: 0.1398 - decision_loss: 0.1365 - argument_accuracy: 0.9549 - decision_accuracy: 0.9781 - val_loss: 0.6448 - val_argument_loss: 0.3438 - val_decision_loss: 0.3010 - val_argument_accuracy: 0.8916 - val_decision_accuracy: 0.9076\n",
            "Epoch 7/15\n",
            "35/35 [==============================] - 45s 1s/step - loss: 0.1997 - argument_loss: 0.1042 - decision_loss: 0.0955 - argument_accuracy: 0.9701 - decision_accuracy: 0.9862 - val_loss: 0.6540 - val_argument_loss: 0.3473 - val_decision_loss: 0.3066 - val_argument_accuracy: 0.8876 - val_decision_accuracy: 0.9076\n",
            "Epoch 8/15\n",
            "35/35 [==============================] - 45s 1s/step - loss: 0.1497 - argument_loss: 0.0708 - decision_loss: 0.0789 - argument_accuracy: 0.9875 - decision_accuracy: 0.9906 - val_loss: 0.7236 - val_argument_loss: 0.3919 - val_decision_loss: 0.3317 - val_argument_accuracy: 0.8876 - val_decision_accuracy: 0.9076\n",
            "Epoch 9/15\n",
            "35/35 [==============================] - 45s 1s/step - loss: 0.1149 - argument_loss: 0.0577 - decision_loss: 0.0572 - argument_accuracy: 0.9911 - decision_accuracy: 0.9942 - val_loss: 0.7027 - val_argument_loss: 0.3952 - val_decision_loss: 0.3075 - val_argument_accuracy: 0.8876 - val_decision_accuracy: 0.9076\n",
            "Epoch 10/15\n",
            "35/35 [==============================] - 45s 1s/step - loss: 0.0890 - argument_loss: 0.0427 - decision_loss: 0.0463 - argument_accuracy: 0.9942 - decision_accuracy: 0.9969 - val_loss: 0.7239 - val_argument_loss: 0.4053 - val_decision_loss: 0.3186 - val_argument_accuracy: 0.8956 - val_decision_accuracy: 0.9157\n",
            "Epoch 11/15\n",
            "35/35 [==============================] - 45s 1s/step - loss: 0.0756 - argument_loss: 0.0379 - decision_loss: 0.0377 - argument_accuracy: 0.9960 - decision_accuracy: 0.9978 - val_loss: 0.7624 - val_argument_loss: 0.4626 - val_decision_loss: 0.2997 - val_argument_accuracy: 0.8916 - val_decision_accuracy: 0.9197\n",
            "Epoch 12/15\n",
            "35/35 [==============================] - 45s 1s/step - loss: 0.0677 - argument_loss: 0.0361 - decision_loss: 0.0316 - argument_accuracy: 0.9933 - decision_accuracy: 0.9978 - val_loss: 0.7578 - val_argument_loss: 0.4341 - val_decision_loss: 0.3237 - val_argument_accuracy: 0.8916 - val_decision_accuracy: 0.9157\n",
            "Epoch 13/15\n",
            "35/35 [==============================] - 45s 1s/step - loss: 0.0531 - argument_loss: 0.0260 - decision_loss: 0.0271 - argument_accuracy: 0.9969 - decision_accuracy: 0.9996 - val_loss: 0.7880 - val_argument_loss: 0.4504 - val_decision_loss: 0.3376 - val_argument_accuracy: 0.8956 - val_decision_accuracy: 0.9157\n",
            "Epoch 14/15\n",
            "35/35 [==============================] - 45s 1s/step - loss: 0.0475 - argument_loss: 0.0224 - decision_loss: 0.0251 - argument_accuracy: 0.9978 - decision_accuracy: 0.9991 - val_loss: 0.8148 - val_argument_loss: 0.4711 - val_decision_loss: 0.3437 - val_argument_accuracy: 0.8916 - val_decision_accuracy: 0.9116\n",
            "Epoch 15/15\n",
            "35/35 [==============================] - 45s 1s/step - loss: 0.0436 - argument_loss: 0.0219 - decision_loss: 0.0216 - argument_accuracy: 0.9973 - decision_accuracy: 0.9996 - val_loss: 0.7962 - val_argument_loss: 0.4593 - val_decision_loss: 0.3369 - val_argument_accuracy: 0.8876 - val_decision_accuracy: 0.9076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2kiSeCDBDXY",
        "outputId": "7f911f13-1d78-445e-9614-fd65d760b92e"
      },
      "source": [
        "# Evaluation\n",
        "testArg = to_categorical(df_test['argument_cat'], 4)\n",
        "testDec = to_categorical(df_test['decision_cat'])\n",
        "testReview = tokenizer(text=df_test['review'].to_list(), add_special_tokens=True,\n",
        "                         max_length=maxLen, truncation=True, padding=True, \n",
        "                         return_tensors='tf', return_token_type_ids = False,\n",
        "                         return_attention_mask = False, verbose = True)\n",
        "modelEval = model.evaluate(x={'input_ids': testReview['input_ids']},\n",
        "                                 y={'argument': testArg, 'decision': testDec})"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 2s 203ms/step - loss: 0.6727 - argument_loss: 0.2738 - decision_loss: 0.3989 - argument_accuracy: 0.9242 - decision_accuracy: 0.9025\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
