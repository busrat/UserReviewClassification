{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvbwu3oCB3MH"
      },
      "source": [
        "!pip install transformers\n",
        "# !pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2DKQmWpB7sQ"
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M1R55dYB-GB"
      },
      "source": [
        "# Import data\n",
        "df = pd.read_csv('app_reviews_all_annotated2.csv')\n",
        "df = df[['review', 'argument_cat', 'decision_cat']]\n",
        "\n",
        "# Remove missing rows\n",
        "df = df.dropna()\n",
        "\n",
        "# Convert to numeric for bert\n",
        "df['Argument'] = pd.Categorical(df['argument_cat'])\n",
        "df['Decision'] = pd.Categorical(df['decision_cat'])\n",
        "df['argument_cat'] = df['Argument'].cat.codes\n",
        "df['decision_cat'] = df['Decision'].cat.codes\n",
        "\n",
        "# Split into training and testing \n",
        "df, df_test = train_test_split(df, test_size = 0.2, stratify = df[['decision_cat']])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGTVvGjlCDHd",
        "outputId": "23549968-7352-4045-c936-e9f6f239b86d"
      },
      "source": [
        "# BERT model\n",
        "modelName = 'bert-base-uncased'\n",
        "maxLen = 100\n",
        "conf = BertConfig.from_pretrained(modelName)\n",
        "conf.output_hidden_states = False\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = modelName, config = conf)\n",
        "\n",
        "# Load transformer BERT model\n",
        "transformerModel = TFBertModel.from_pretrained(modelName, config = conf)\n",
        "\n",
        "bert = transformerModel.layers[0]\n",
        "inputIds = Input(shape=(maxLen,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': inputIds}\n",
        "\n",
        "bertModel = bert(inputs)[1]\n",
        "dropout = Dropout(conf.hidden_dropout_prob, name='pooled_output')\n",
        "pooledOutput = dropout(bertModel, training=False)\n",
        "\n",
        "arg = Dense(units=len(df.argument_cat.value_counts()), kernel_initializer=TruncatedNormal(stddev=conf.initializer_range), name='argument')(pooledOutput)\n",
        "dec = Dense(units=len(df.decision_cat.value_counts()), kernel_initializer=TruncatedNormal(stddev=conf.initializer_range), name='decision')(pooledOutput)\n",
        "outputs = {'argument': arg, 'decision': dec}\n",
        "\n",
        "# Show model\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_For_App_Review_Classification')\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"BERT_For_App_Review_Classification\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert (TFBertMainLayer)          TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pooled_output (Dropout)         (None, 768)          0           bert[0][1]                       \n",
            "__________________________________________________________________________________________________\n",
            "argument (Dense)                (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decision (Dense)                (None, 5)            3845        pooled_output[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 109,489,161\n",
            "Trainable params: 109,489,161\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heBO_9Lq-cBJ",
        "outputId": "b4395c3f-c24a-44b2-de5e-26d13aef879e"
      },
      "source": [
        "# Training\n",
        "optimizer = Adam(learning_rate=5e-05, epsilon=1e-08, decay=0.01, clipnorm=1.0)\n",
        "loss = {'argument': CategoricalCrossentropy(from_logits = True), 'decision': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'argument': CategoricalAccuracy('accuracy'), 'decision': CategoricalAccuracy('accuracy')}\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = metric)\n",
        "\n",
        "x = tokenizer(text=df.review.to_list(), add_special_tokens=True, max_length=maxLen, \n",
        "              truncation=True, padding=True, return_tensors='tf', return_token_type_ids = False,\n",
        "              return_attention_mask = True, verbose = True)\n",
        "\n",
        "history = model.fit(x={'input_ids': x['input_ids']}, y={'argument': to_categorical(df.argument_cat), 'decision': to_categorical(df.decision_cat)},\n",
        "                    validation_split=0.2, batch_size=64, epochs=10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "28/28 [==============================] - 55s 1s/step - loss: 1.8965 - argument_loss: 0.5208 - decision_loss: 1.3758 - argument_accuracy: 0.8445 - decision_accuracy: 0.4449 - val_loss: 1.7620 - val_argument_loss: 0.3963 - val_decision_loss: 1.3656 - val_argument_accuracy: 0.8352 - val_decision_accuracy: 0.4470\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 35s 1s/step - loss: 1.5419 - argument_loss: 0.3322 - decision_loss: 1.2097 - argument_accuracy: 0.8717 - decision_accuracy: 0.5042 - val_loss: 1.4296 - val_argument_loss: 0.3403 - val_decision_loss: 1.0892 - val_argument_accuracy: 0.8713 - val_decision_accuracy: 0.5801\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 35s 1s/step - loss: 1.1353 - argument_loss: 0.2876 - decision_loss: 0.8477 - argument_accuracy: 0.8999 - decision_accuracy: 0.6914 - val_loss: 0.9941 - val_argument_loss: 0.3439 - val_decision_loss: 0.6502 - val_argument_accuracy: 0.8736 - val_decision_accuracy: 0.8262\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 35s 1s/step - loss: 0.7393 - argument_loss: 0.2541 - decision_loss: 0.4851 - argument_accuracy: 0.9243 - decision_accuracy: 0.8773 - val_loss: 0.6729 - val_argument_loss: 0.2632 - val_decision_loss: 0.4097 - val_argument_accuracy: 0.9097 - val_decision_accuracy: 0.8939\n",
            "Epoch 5/10\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.5020 - argument_loss: 0.2105 - decision_loss: 0.2915 - argument_accuracy: 0.9299 - decision_accuracy: 0.9316 - val_loss: 0.6229 - val_argument_loss: 0.2784 - val_decision_loss: 0.3445 - val_argument_accuracy: 0.9029 - val_decision_accuracy: 0.9074\n",
            "Epoch 6/10\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.3647 - argument_loss: 0.1848 - decision_loss: 0.1799 - argument_accuracy: 0.9378 - decision_accuracy: 0.9689 - val_loss: 0.6029 - val_argument_loss: 0.2795 - val_decision_loss: 0.3234 - val_argument_accuracy: 0.8962 - val_decision_accuracy: 0.8984\n",
            "Epoch 7/10\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.2563 - argument_loss: 0.1279 - decision_loss: 0.1284 - argument_accuracy: 0.9666 - decision_accuracy: 0.9802 - val_loss: 0.6710 - val_argument_loss: 0.3464 - val_decision_loss: 0.3246 - val_argument_accuracy: 0.8894 - val_decision_accuracy: 0.9029\n",
            "Epoch 8/10\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.2003 - argument_loss: 0.1000 - decision_loss: 0.1002 - argument_accuracy: 0.9734 - decision_accuracy: 0.9864 - val_loss: 0.6251 - val_argument_loss: 0.3199 - val_decision_loss: 0.3051 - val_argument_accuracy: 0.9007 - val_decision_accuracy: 0.9120\n",
            "Epoch 9/10\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.1400 - argument_loss: 0.0674 - decision_loss: 0.0727 - argument_accuracy: 0.9893 - decision_accuracy: 0.9938 - val_loss: 0.6204 - val_argument_loss: 0.3009 - val_decision_loss: 0.3195 - val_argument_accuracy: 0.9074 - val_decision_accuracy: 0.9097\n",
            "Epoch 10/10\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.1176 - argument_loss: 0.0564 - decision_loss: 0.0612 - argument_accuracy: 0.9927 - decision_accuracy: 0.9960 - val_loss: 0.6335 - val_argument_loss: 0.3243 - val_decision_loss: 0.3092 - val_argument_accuracy: 0.9074 - val_decision_accuracy: 0.9120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJUBlcC0B02y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2kiSeCDBDXY",
        "outputId": "c8e590d3-92b1-404a-ed7c-32c568964cb1"
      },
      "source": [
        "# Evaluation\n",
        "testArg = to_categorical(df_test.argument_cat)\n",
        "testDec = to_categorical(df_test.decision_cat)\n",
        "testReview = tokenizer(text=df_test['review'].to_list(), add_special_tokens=True,\n",
        "                         max_length=maxLen, truncation=True, padding=True, \n",
        "                         return_tensors='tf', return_token_type_ids = False,\n",
        "                         return_attention_mask = False, verbose = True)\n",
        "#modelEvalForArg = model.evaluate(x={'input_ids': testReview['input_ids']}, y={'argument': testArg})\n",
        "modelEvalForDec = model.evaluate(x={'input_ids': testReview['input_ids']}, y={'decision': testDec})"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 4s 193ms/step - loss: 0.3829 - argument_loss: 0.0000e+00 - decision_loss: 0.3829 - argument_accuracy: 0.0000e+00 - decision_accuracy: 0.8987\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
